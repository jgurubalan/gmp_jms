{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf88d1ce",
   "metadata": {},
   "source": [
    "### <span style=\"color:teal\"> __TAXONOMY DICTIONARY MAPPING__\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63030bc4",
   "metadata": {},
   "source": [
    "This methodology resolves scientific names and phylum-level classifications for NCBI TaxIDs in two stages, with batching, fallbacks, and rate-limit safeguards. First, it collects all unique `ncbi_taxon_id` values from the dataset and queries **NCBI E-utilities (esummary, db=taxonomy)** in batches (size 200) using a provided API key; for each TaxID, it prefers the **species-rank** scientific name and otherwise falls back to whatever rank returns a scientific name. Any IDs not resolved by NCBI are retried against the **UniProt Taxonomy REST API** as a fallback; unresolved entries are labeled `\"Unknown\"`. This produces a `taxon_dict` mapping TaxID â†’ scientific name, which is saved to JSON and accompanied by a small summary report (counts resolved via NCBI, via UniProt, and unresolved). In the second stage, the code retrieves **taxonomy XML** from NCBI (efetch, db=taxonomy) in batches (size 100) and parses each `<Taxon>` recordâ€™s `LineageEx` to extract the ancestor whose `<Rank>` equals `\"phylum\"`, recording that ancestorâ€™s `<ScientificName>`; if no phylum is located, it marks the entry as `\"phylum_Not_Found\"`, and if the batch fails twice it records `\"Error\"`. The workflow respects NCBIâ€™s rate guidelines with short sleeps between requests (âˆ¼0.34â€“0.40 s), handles HTTP errors gracefully, and skips the sentinel `-1` by assigning `\"Unknown\"` up front (while still including it in the final mapping for completeness). The outputsâ€”**`taxon_dict.json`** (TaxID â†’ scientific name) and **`taxon_phyla_dict.json`** (TaxID â†’ phylum)â€”are persisted for **downstream analyses**, enabling consistent taxon naming and robust phylum-level grouping/filtering without re-querying external services; the latter file is derived strictly from parsed lineage and serves as a compact classification layer suitable for stratification, summaries, or QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98a13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9993775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset (GMRepo 'species_abundance.txt')\n",
    "df = pd.read_csv(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gm_repository/species_abundance.txt\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCBI Batch lookup:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCBI Batch lookup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:35<00:00,  1.26it/s]\n",
      "UniProt fallback: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:41<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Taxonomic Name Resolution Summary\n",
      "------------------------------------\n",
      "ðŸ”¹ Total Taxon IDs Provided     : 8910\n",
      "ðŸ”¹ Resolved from NCBI           : 8818\n",
      "ðŸ”¹ Resolved from UniProt        : 91\n",
      "ðŸ”¹ Unresolved IDs               : 1\n",
      "ðŸ”¹ Final Entries in Dictionary  : 8910\n",
      "\n",
      "ðŸ’¾ Files saved:\n",
      " - taxon_dict.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "taxon_id = df['ncbi_taxon_id'].unique()\n",
    "#get update taxonomy species ID from NCBI or uniprot\n",
    "\n",
    "API_KEY = \"87fdd45a6ee743fecdbd1b7e9f010d669109\"\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# Ensure your taxon_id list exists and convert to strings\n",
    "taxon_id = [str(x) for x in taxon_id]\n",
    "\n",
    "# Final dictionary and counters\n",
    "taxon_dict = {}\n",
    "from_ncbi = 0\n",
    "from_uniprot = 0\n",
    "unresolved = 0\n",
    "\n",
    "def fetch_ncbi_batch(batch_ids):\n",
    "    \"\"\"Query NCBI for names (species preferred, fallback to higher rank).\"\"\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "    params = {\n",
    "        'db': 'taxonomy',\n",
    "        'id': \",\".join(batch_ids),\n",
    "        'retmode': 'json',\n",
    "        'api_key': API_KEY\n",
    "    }\n",
    "    species = {}\n",
    "    fallback = {}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            result = r.json().get(\"result\", {})\n",
    "            for tid in batch_ids:\n",
    "                record = result.get(tid, {})\n",
    "                name = record.get(\"scientificname\")\n",
    "                rank = record.get(\"rank\", \"\")\n",
    "                if name:\n",
    "                    if rank == \"species\":\n",
    "                        species[tid] = name\n",
    "                    else:\n",
    "                        fallback[tid] = name\n",
    "    except Exception as e:\n",
    "        print(f\" NCBI error for {batch_ids[:3]}: {e}\")\n",
    "    return species, fallback\n",
    "\n",
    "def get_name_from_uniprot(tax_id):\n",
    "    \"\"\"Query UniProt as fallback.\"\"\"\n",
    "    url = f\"https://rest.uniprot.org/taxonomy/{tax_id}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            return r.json().get(\"scientificName\")\n",
    "    except Exception as e:\n",
    "        print(f\" UniProt error for {tax_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Step 1: Query NCBI\n",
    "missing_ids = []\n",
    "for i in tqdm(range(0, len(taxon_id), BATCH_SIZE), desc=\"NCBI Batch lookup\"):\n",
    "    batch = taxon_id[i:i+BATCH_SIZE]\n",
    "    species_dict, fallback_dict = fetch_ncbi_batch(batch)\n",
    "\n",
    "    for tid in batch:\n",
    "        tid_int = int(tid)\n",
    "        if tid in species_dict:\n",
    "            taxon_dict[tid_int] = species_dict[tid]\n",
    "            from_ncbi += 1\n",
    "        elif tid in fallback_dict:\n",
    "            taxon_dict[tid_int] = fallback_dict[tid]\n",
    "            from_ncbi += 1\n",
    "        else:\n",
    "            missing_ids.append(tid)\n",
    "\n",
    "    time.sleep(0.4)  # NCBI rate limit\n",
    "\n",
    "# Step 2: Query UniProt\n",
    "for tid in tqdm(missing_ids, desc=\"UniProt fallback\"):\n",
    "    name = get_name_from_uniprot(tid)\n",
    "    tid_int = int(tid)\n",
    "    if name:\n",
    "        taxon_dict[tid_int] = name\n",
    "        from_uniprot += 1\n",
    "    else:\n",
    "        taxon_dict[tid_int] = \"Unknown\"\n",
    "        unresolved += 1\n",
    "\n",
    "# Step 3: Save the complete dictionary\n",
    "with open(\"taxon_dict.json\", \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in taxon_dict.items()}, f, indent=2)\n",
    "\n",
    "# Step 4: Report summary\n",
    "print(\"\\nâœ… Taxonomic Name Resolution Summary\")\n",
    "print(\"------------------------------------\")\n",
    "print(f\"ðŸ”¹ Total Taxon IDs Provided     : {len(taxon_id)}\")\n",
    "print(f\"ðŸ”¹ Resolved from NCBI           : {from_ncbi}\")\n",
    "print(f\"ðŸ”¹ Resolved from UniProt        : {from_uniprot}\")\n",
    "print(f\"ðŸ”¹ Unresolved IDs               : {unresolved}\")\n",
    "print(f\"ðŸ”¹ Final Entries in Dictionary  : {len(taxon_dict)}\")\n",
    "\n",
    "\n",
    "# Save final dictionary\n",
    "with open(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gmp_jms/taxon_dict.json\", \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in taxon_dict.items()}, f, indent=2)\n",
    "\n",
    "print(\"\\nðŸ’¾ Files saved:\")\n",
    "print(\" - taxon_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98154785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Processing batch 1 to 100 of 8910...\n",
      "ðŸ” Processing batch 101 to 200 of 8910...\n",
      "ðŸ” Processing batch 201 to 300 of 8910...\n",
      "ðŸ” Processing batch 301 to 400 of 8910...\n",
      "ðŸ” Processing batch 401 to 500 of 8910...\n",
      "ðŸ” Processing batch 501 to 600 of 8910...\n",
      "ðŸ” Processing batch 601 to 700 of 8910...\n",
      "ðŸ” Processing batch 701 to 800 of 8910...\n",
      "ðŸ” Processing batch 801 to 900 of 8910...\n",
      "ðŸ” Processing batch 901 to 1000 of 8910...\n",
      "ðŸ” Processing batch 1001 to 1100 of 8910...\n",
      "ðŸ” Processing batch 1101 to 1200 of 8910...\n",
      "ðŸ” Processing batch 1201 to 1300 of 8910...\n",
      "ðŸ” Processing batch 1301 to 1400 of 8910...\n",
      "ðŸ” Processing batch 1401 to 1500 of 8910...\n",
      "ðŸ” Processing batch 1501 to 1600 of 8910...\n",
      "ðŸ” Processing batch 1601 to 1700 of 8910...\n",
      "ðŸ” Processing batch 1701 to 1800 of 8910...\n",
      "ðŸ” Processing batch 1801 to 1900 of 8910...\n",
      "ðŸ” Processing batch 1901 to 2000 of 8910...\n",
      "ðŸ” Processing batch 2001 to 2100 of 8910...\n",
      "ðŸ” Processing batch 2101 to 2200 of 8910...\n",
      "ðŸ” Processing batch 2201 to 2300 of 8910...\n",
      "ðŸ” Processing batch 2301 to 2400 of 8910...\n",
      "ðŸ” Processing batch 2401 to 2500 of 8910...\n",
      "ðŸ” Processing batch 2501 to 2600 of 8910...\n",
      "ðŸ” Processing batch 2601 to 2700 of 8910...\n",
      "ðŸ” Processing batch 2701 to 2800 of 8910...\n",
      "ðŸ” Processing batch 2801 to 2900 of 8910...\n",
      "ðŸ” Processing batch 2901 to 3000 of 8910...\n",
      "ðŸ” Processing batch 3001 to 3100 of 8910...\n",
      "ðŸ” Processing batch 3101 to 3200 of 8910...\n",
      "ðŸ” Processing batch 3201 to 3300 of 8910...\n",
      "ðŸ” Processing batch 3301 to 3400 of 8910...\n",
      "ðŸ” Processing batch 3401 to 3500 of 8910...\n",
      "ðŸ” Processing batch 3501 to 3600 of 8910...\n",
      "ðŸ” Processing batch 3601 to 3700 of 8910...\n",
      "ðŸ” Processing batch 3701 to 3800 of 8910...\n",
      "ðŸ” Processing batch 3801 to 3900 of 8910...\n",
      "ðŸ” Processing batch 3901 to 4000 of 8910...\n",
      "ðŸ” Processing batch 4001 to 4100 of 8910...\n",
      "ðŸ” Processing batch 4101 to 4200 of 8910...\n",
      "ðŸ” Processing batch 4201 to 4300 of 8910...\n",
      "ðŸ” Processing batch 4301 to 4400 of 8910...\n",
      "ðŸ” Processing batch 4401 to 4500 of 8910...\n",
      "ðŸ” Processing batch 4501 to 4600 of 8910...\n",
      "ðŸ” Processing batch 4601 to 4700 of 8910...\n",
      "ðŸ” Processing batch 4701 to 4800 of 8910...\n",
      "ðŸ” Processing batch 4801 to 4900 of 8910...\n",
      "ðŸ” Processing batch 4901 to 5000 of 8910...\n",
      "ðŸ” Processing batch 5001 to 5100 of 8910...\n",
      "ðŸ” Processing batch 5101 to 5200 of 8910...\n",
      "ðŸ” Processing batch 5201 to 5300 of 8910...\n",
      "ðŸ” Processing batch 5301 to 5400 of 8910...\n",
      "ðŸ” Processing batch 5401 to 5500 of 8910...\n",
      "ðŸ” Processing batch 5501 to 5600 of 8910...\n",
      "ðŸ” Processing batch 5601 to 5700 of 8910...\n",
      "ðŸ” Processing batch 5701 to 5800 of 8910...\n",
      "ðŸ” Processing batch 5801 to 5900 of 8910...\n",
      "ðŸ” Processing batch 5901 to 6000 of 8910...\n",
      "ðŸ” Processing batch 6001 to 6100 of 8910...\n",
      "ðŸ” Processing batch 6101 to 6200 of 8910...\n",
      "ðŸ” Processing batch 6201 to 6300 of 8910...\n",
      "ðŸ” Processing batch 6301 to 6400 of 8910...\n",
      "ðŸ” Processing batch 6401 to 6500 of 8910...\n",
      "ðŸ” Processing batch 6501 to 6600 of 8910...\n",
      "ðŸ” Processing batch 6601 to 6700 of 8910...\n",
      "ðŸ” Processing batch 6701 to 6800 of 8910...\n",
      "ðŸ” Processing batch 6801 to 6900 of 8910...\n",
      "ðŸ” Processing batch 6901 to 7000 of 8910...\n",
      "ðŸ” Processing batch 7001 to 7100 of 8910...\n",
      "ðŸ” Processing batch 7101 to 7200 of 8910...\n",
      "ðŸ” Processing batch 7201 to 7300 of 8910...\n",
      "ðŸ” Processing batch 7301 to 7400 of 8910...\n",
      "ðŸ” Processing batch 7401 to 7500 of 8910...\n",
      "ðŸ” Processing batch 7501 to 7600 of 8910...\n",
      "ðŸ” Processing batch 7601 to 7700 of 8910...\n",
      "ðŸ” Processing batch 7701 to 7800 of 8910...\n",
      "ðŸ” Processing batch 7801 to 7900 of 8910...\n",
      "ðŸ” Processing batch 7901 to 8000 of 8910...\n",
      "ðŸ” Processing batch 8001 to 8100 of 8910...\n",
      "ðŸ” Processing batch 8101 to 8200 of 8910...\n",
      "ðŸ” Processing batch 8201 to 8300 of 8910...\n",
      "ðŸ” Processing batch 8301 to 8400 of 8910...\n",
      "ðŸ” Processing batch 8401 to 8500 of 8910...\n",
      "ðŸ” Processing batch 8501 to 8600 of 8910...\n",
      "ðŸ” Processing batch 8601 to 8700 of 8910...\n",
      "ðŸ” Processing batch 8701 to 8800 of 8910...\n",
      "ðŸ” Processing batch 8801 to 8900 of 8910...\n",
      "ðŸ” Processing batch 8901 to 8910 of 8910...\n",
      "Number of unique values: 48\n",
      "âœ… Done! Orders saved to 'taxon_to_phyla.json'\n"
     ]
    }
   ],
   "source": [
    "# === Your API key here\n",
    "NCBI_API_KEY = \"87fdd45a6ee743fecdbd1b7e9f010d669109\"\n",
    "\n",
    "# === Function to fetch taxonomy XML for a batch of taxon IDs\n",
    "def fetch_phylum_batch(taxon_ids):\n",
    "    joined_ids = \",\".join(str(t) for t in taxon_ids)\n",
    "    params = {\n",
    "        \"db\": \"taxonomy\",\n",
    "        \"id\": joined_ids,\n",
    "        \"retmode\": \"xml\",\n",
    "        \"api_key\": NCBI_API_KEY\n",
    "    }\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error fetching batch {taxon_ids[:3]}...: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Main script to fetch phylum for each TaxID\n",
    "def batch_get_phylum(taxon_dict, batch_size=100):\n",
    "    all_taxids = [int(tid) for tid in taxon_dict.keys() if tid != \"-1\"]\n",
    "    taxon_phylum_map = {\"-1\": \"Unknown\"}\n",
    "\n",
    "    for i in range(0, len(all_taxids), batch_size):\n",
    "        batch = all_taxids[i:i + batch_size]\n",
    "        print(f\"ðŸ” Processing batch {i+1} to {i+len(batch)} of {len(all_taxids)}...\")\n",
    "\n",
    "        xml_data = fetch_phylum_batch(batch)\n",
    "        if not xml_data:\n",
    "            # Retry once after delay\n",
    "            time.sleep(1)\n",
    "            xml_data = fetch_phylum_batch(batch)\n",
    "            if not xml_data:\n",
    "                for tid in batch:\n",
    "                    taxon_phylum_map[str(tid)] = \"Error\"\n",
    "                continue\n",
    "\n",
    "        # Parse each Taxon block individually\n",
    "        root = ET.fromstring(xml_data)\n",
    "        for taxon in root.findall(\"Taxon\"):\n",
    "            tid = taxon.findtext(\"TaxId\")\n",
    "            phylum_name = \"phylum_Not_Found\"\n",
    "\n",
    "            for ancestor in taxon.findall(\".//LineageEx/Taxon\"):\n",
    "                if ancestor.findtext(\"Rank\") == \"phylum\":\n",
    "                    phylum_name = ancestor.findtext(\"ScientificName\")\n",
    "                    break\n",
    "\n",
    "            taxon_phylum_map[tid] = phylum_name\n",
    "\n",
    "        time.sleep(0.34)  # NCBI rate limit: keep <3 requests/sec\n",
    "\n",
    "    return taxon_phylum_map\n",
    "\n",
    "# === Example usage\n",
    "# taxon_dict = {\"562\": \"Escherichia coli\", \"1280\": \"Lactobacillus\", ...}\n",
    "output_dict = batch_get_phylum(taxon_dict, batch_size=100)\n",
    "\n",
    "unique_values = set(output_dict.values())\n",
    "print(f\"Number of unique values: {len(unique_values)}\")\n",
    "\n",
    "# === Save to JSON\n",
    "with open(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gmp_jms/taxon_phyla_dict.json\", \"w\") as f:\n",
    "    json.dump(output_dict, f, indent=2)\n",
    "\n",
    "print(\"âœ… Done! Orders saved to 'taxon_to_phyla.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mam_myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
