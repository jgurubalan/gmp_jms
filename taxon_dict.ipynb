{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf88d1ce",
   "metadata": {},
   "source": [
    "### <span style=\"color:teal\"> __TAXONOMY DICTIONARY MAPPING__\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63030bc4",
   "metadata": {},
   "source": [
    "This methodology resolves scientific names and phylum-level classifications for NCBI TaxIDs in two stages, with batching, fallbacks, and rate-limit safeguards. First, it collects all unique `ncbi_taxon_id` values from the dataset and queries **NCBI E-utilities (esummary, db=taxonomy)** in batches (size 200) using a provided API key; for each TaxID, it prefers the **species-rank** scientific name and otherwise falls back to whatever rank returns a scientific name. Any IDs not resolved by NCBI are retried against the **UniProt Taxonomy REST API** as a fallback; unresolved entries are labeled `\"Unknown\"`. This produces a `taxon_dict` mapping TaxID → scientific name, which is saved to JSON and accompanied by a small summary report (counts resolved via NCBI, via UniProt, and unresolved). In the second stage, the code retrieves **taxonomy XML** from NCBI (efetch, db=taxonomy) in batches (size 100) and parses each `<Taxon>` record’s `LineageEx` to extract the ancestor whose `<Rank>` equals `\"phylum\"`, recording that ancestor’s `<ScientificName>`; if no phylum is located, it marks the entry as `\"phylum_Not_Found\"`, and if the batch fails twice it records `\"Error\"`. The workflow respects NCBI’s rate guidelines with short sleeps between requests (∼0.34–0.40 s), handles HTTP errors gracefully, and skips the sentinel `-1` by assigning `\"Unknown\"` up front (while still including it in the final mapping for completeness). The outputs—**`taxon_dict.json`** (TaxID → scientific name) and **`taxon_phyla_dict.json`** (TaxID → phylum)—are persisted for **downstream analyses**, enabling consistent taxon naming and robust phylum-level grouping/filtering without re-querying external services; the latter file is derived strictly from parsed lineage and serves as a compact classification layer suitable for stratification, summaries, or QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98a13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9993775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset (GMRepo 'species_abundance.txt')\n",
    "df = pd.read_csv(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gm_repository/species_abundance.txt\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCBI Batch lookup:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCBI Batch lookup: 100%|██████████| 45/45 [00:35<00:00,  1.26it/s]\n",
      "UniProt fallback: 100%|██████████| 92/92 [00:41<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Taxonomic Name Resolution Summary\n",
      "------------------------------------\n",
      "🔹 Total Taxon IDs Provided     : 8910\n",
      "🔹 Resolved from NCBI           : 8818\n",
      "🔹 Resolved from UniProt        : 91\n",
      "🔹 Unresolved IDs               : 1\n",
      "🔹 Final Entries in Dictionary  : 8910\n",
      "\n",
      "💾 Files saved:\n",
      " - taxon_dict.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "taxon_id = df['ncbi_taxon_id'].unique()\n",
    "#get update taxonomy species ID from NCBI or uniprot\n",
    "\n",
    "API_KEY = \"87fdd45a6ee743fecdbd1b7e9f010d669109\"\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# Ensure your taxon_id list exists and convert to strings\n",
    "taxon_id = [str(x) for x in taxon_id]\n",
    "\n",
    "# Final dictionary and counters\n",
    "taxon_dict = {}\n",
    "from_ncbi = 0\n",
    "from_uniprot = 0\n",
    "unresolved = 0\n",
    "\n",
    "def fetch_ncbi_batch(batch_ids):\n",
    "    \"\"\"Query NCBI for names (species preferred, fallback to higher rank).\"\"\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "    params = {\n",
    "        'db': 'taxonomy',\n",
    "        'id': \",\".join(batch_ids),\n",
    "        'retmode': 'json',\n",
    "        'api_key': API_KEY\n",
    "    }\n",
    "    species = {}\n",
    "    fallback = {}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            result = r.json().get(\"result\", {})\n",
    "            for tid in batch_ids:\n",
    "                record = result.get(tid, {})\n",
    "                name = record.get(\"scientificname\")\n",
    "                rank = record.get(\"rank\", \"\")\n",
    "                if name:\n",
    "                    if rank == \"species\":\n",
    "                        species[tid] = name\n",
    "                    else:\n",
    "                        fallback[tid] = name\n",
    "    except Exception as e:\n",
    "        print(f\" NCBI error for {batch_ids[:3]}: {e}\")\n",
    "    return species, fallback\n",
    "\n",
    "def get_name_from_uniprot(tax_id):\n",
    "    \"\"\"Query UniProt as fallback.\"\"\"\n",
    "    url = f\"https://rest.uniprot.org/taxonomy/{tax_id}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            return r.json().get(\"scientificName\")\n",
    "    except Exception as e:\n",
    "        print(f\" UniProt error for {tax_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Step 1: Query NCBI\n",
    "missing_ids = []\n",
    "for i in tqdm(range(0, len(taxon_id), BATCH_SIZE), desc=\"NCBI Batch lookup\"):\n",
    "    batch = taxon_id[i:i+BATCH_SIZE]\n",
    "    species_dict, fallback_dict = fetch_ncbi_batch(batch)\n",
    "\n",
    "    for tid in batch:\n",
    "        tid_int = int(tid)\n",
    "        if tid in species_dict:\n",
    "            taxon_dict[tid_int] = species_dict[tid]\n",
    "            from_ncbi += 1\n",
    "        elif tid in fallback_dict:\n",
    "            taxon_dict[tid_int] = fallback_dict[tid]\n",
    "            from_ncbi += 1\n",
    "        else:\n",
    "            missing_ids.append(tid)\n",
    "\n",
    "    time.sleep(0.4)  # NCBI rate limit\n",
    "\n",
    "# Step 2: Query UniProt\n",
    "for tid in tqdm(missing_ids, desc=\"UniProt fallback\"):\n",
    "    name = get_name_from_uniprot(tid)\n",
    "    tid_int = int(tid)\n",
    "    if name:\n",
    "        taxon_dict[tid_int] = name\n",
    "        from_uniprot += 1\n",
    "    else:\n",
    "        taxon_dict[tid_int] = \"Unknown\"\n",
    "        unresolved += 1\n",
    "\n",
    "# Step 3: Save the complete dictionary\n",
    "with open(\"taxon_dict.json\", \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in taxon_dict.items()}, f, indent=2)\n",
    "\n",
    "# Step 4: Report summary\n",
    "print(\"\\n✅ Taxonomic Name Resolution Summary\")\n",
    "print(\"------------------------------------\")\n",
    "print(f\"🔹 Total Taxon IDs Provided     : {len(taxon_id)}\")\n",
    "print(f\"🔹 Resolved from NCBI           : {from_ncbi}\")\n",
    "print(f\"🔹 Resolved from UniProt        : {from_uniprot}\")\n",
    "print(f\"🔹 Unresolved IDs               : {unresolved}\")\n",
    "print(f\"🔹 Final Entries in Dictionary  : {len(taxon_dict)}\")\n",
    "\n",
    "\n",
    "# Save final dictionary\n",
    "with open(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gmp_jms/taxon_dict.json\", \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in taxon_dict.items()}, f, indent=2)\n",
    "\n",
    "print(\"\\n💾 Files saved:\")\n",
    "print(\" - taxon_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98154785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Processing batch 1 to 100 of 8910...\n",
      "🔍 Processing batch 101 to 200 of 8910...\n",
      "🔍 Processing batch 201 to 300 of 8910...\n",
      "🔍 Processing batch 301 to 400 of 8910...\n",
      "🔍 Processing batch 401 to 500 of 8910...\n",
      "🔍 Processing batch 501 to 600 of 8910...\n",
      "🔍 Processing batch 601 to 700 of 8910...\n",
      "🔍 Processing batch 701 to 800 of 8910...\n",
      "🔍 Processing batch 801 to 900 of 8910...\n",
      "🔍 Processing batch 901 to 1000 of 8910...\n",
      "🔍 Processing batch 1001 to 1100 of 8910...\n",
      "🔍 Processing batch 1101 to 1200 of 8910...\n",
      "🔍 Processing batch 1201 to 1300 of 8910...\n",
      "🔍 Processing batch 1301 to 1400 of 8910...\n",
      "🔍 Processing batch 1401 to 1500 of 8910...\n",
      "🔍 Processing batch 1501 to 1600 of 8910...\n",
      "🔍 Processing batch 1601 to 1700 of 8910...\n",
      "🔍 Processing batch 1701 to 1800 of 8910...\n",
      "🔍 Processing batch 1801 to 1900 of 8910...\n",
      "🔍 Processing batch 1901 to 2000 of 8910...\n",
      "🔍 Processing batch 2001 to 2100 of 8910...\n",
      "🔍 Processing batch 2101 to 2200 of 8910...\n",
      "🔍 Processing batch 2201 to 2300 of 8910...\n",
      "🔍 Processing batch 2301 to 2400 of 8910...\n",
      "🔍 Processing batch 2401 to 2500 of 8910...\n",
      "🔍 Processing batch 2501 to 2600 of 8910...\n",
      "🔍 Processing batch 2601 to 2700 of 8910...\n",
      "🔍 Processing batch 2701 to 2800 of 8910...\n",
      "🔍 Processing batch 2801 to 2900 of 8910...\n",
      "🔍 Processing batch 2901 to 3000 of 8910...\n",
      "🔍 Processing batch 3001 to 3100 of 8910...\n",
      "🔍 Processing batch 3101 to 3200 of 8910...\n",
      "🔍 Processing batch 3201 to 3300 of 8910...\n",
      "🔍 Processing batch 3301 to 3400 of 8910...\n",
      "🔍 Processing batch 3401 to 3500 of 8910...\n",
      "🔍 Processing batch 3501 to 3600 of 8910...\n",
      "🔍 Processing batch 3601 to 3700 of 8910...\n",
      "🔍 Processing batch 3701 to 3800 of 8910...\n",
      "🔍 Processing batch 3801 to 3900 of 8910...\n",
      "🔍 Processing batch 3901 to 4000 of 8910...\n",
      "🔍 Processing batch 4001 to 4100 of 8910...\n",
      "🔍 Processing batch 4101 to 4200 of 8910...\n",
      "🔍 Processing batch 4201 to 4300 of 8910...\n",
      "🔍 Processing batch 4301 to 4400 of 8910...\n",
      "🔍 Processing batch 4401 to 4500 of 8910...\n",
      "🔍 Processing batch 4501 to 4600 of 8910...\n",
      "🔍 Processing batch 4601 to 4700 of 8910...\n",
      "🔍 Processing batch 4701 to 4800 of 8910...\n",
      "🔍 Processing batch 4801 to 4900 of 8910...\n",
      "🔍 Processing batch 4901 to 5000 of 8910...\n",
      "🔍 Processing batch 5001 to 5100 of 8910...\n",
      "🔍 Processing batch 5101 to 5200 of 8910...\n",
      "🔍 Processing batch 5201 to 5300 of 8910...\n",
      "🔍 Processing batch 5301 to 5400 of 8910...\n",
      "🔍 Processing batch 5401 to 5500 of 8910...\n",
      "🔍 Processing batch 5501 to 5600 of 8910...\n",
      "🔍 Processing batch 5601 to 5700 of 8910...\n",
      "🔍 Processing batch 5701 to 5800 of 8910...\n",
      "🔍 Processing batch 5801 to 5900 of 8910...\n",
      "🔍 Processing batch 5901 to 6000 of 8910...\n",
      "🔍 Processing batch 6001 to 6100 of 8910...\n",
      "🔍 Processing batch 6101 to 6200 of 8910...\n",
      "🔍 Processing batch 6201 to 6300 of 8910...\n",
      "🔍 Processing batch 6301 to 6400 of 8910...\n",
      "🔍 Processing batch 6401 to 6500 of 8910...\n",
      "🔍 Processing batch 6501 to 6600 of 8910...\n",
      "🔍 Processing batch 6601 to 6700 of 8910...\n",
      "🔍 Processing batch 6701 to 6800 of 8910...\n",
      "🔍 Processing batch 6801 to 6900 of 8910...\n",
      "🔍 Processing batch 6901 to 7000 of 8910...\n",
      "🔍 Processing batch 7001 to 7100 of 8910...\n",
      "🔍 Processing batch 7101 to 7200 of 8910...\n",
      "🔍 Processing batch 7201 to 7300 of 8910...\n",
      "🔍 Processing batch 7301 to 7400 of 8910...\n",
      "🔍 Processing batch 7401 to 7500 of 8910...\n",
      "🔍 Processing batch 7501 to 7600 of 8910...\n",
      "🔍 Processing batch 7601 to 7700 of 8910...\n",
      "🔍 Processing batch 7701 to 7800 of 8910...\n",
      "🔍 Processing batch 7801 to 7900 of 8910...\n",
      "🔍 Processing batch 7901 to 8000 of 8910...\n",
      "🔍 Processing batch 8001 to 8100 of 8910...\n",
      "🔍 Processing batch 8101 to 8200 of 8910...\n",
      "🔍 Processing batch 8201 to 8300 of 8910...\n",
      "🔍 Processing batch 8301 to 8400 of 8910...\n",
      "🔍 Processing batch 8401 to 8500 of 8910...\n",
      "🔍 Processing batch 8501 to 8600 of 8910...\n",
      "🔍 Processing batch 8601 to 8700 of 8910...\n",
      "🔍 Processing batch 8701 to 8800 of 8910...\n",
      "🔍 Processing batch 8801 to 8900 of 8910...\n",
      "🔍 Processing batch 8901 to 8910 of 8910...\n",
      "Number of unique values: 48\n",
      "✅ Done! Orders saved to 'taxon_to_phyla.json'\n"
     ]
    }
   ],
   "source": [
    "# === Your API key here\n",
    "NCBI_API_KEY = \"87fdd45a6ee743fecdbd1b7e9f010d669109\"\n",
    "\n",
    "# === Function to fetch taxonomy XML for a batch of taxon IDs\n",
    "def fetch_phylum_batch(taxon_ids):\n",
    "    joined_ids = \",\".join(str(t) for t in taxon_ids)\n",
    "    params = {\n",
    "        \"db\": \"taxonomy\",\n",
    "        \"id\": joined_ids,\n",
    "        \"retmode\": \"xml\",\n",
    "        \"api_key\": NCBI_API_KEY\n",
    "    }\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error fetching batch {taxon_ids[:3]}...: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Main script to fetch phylum for each TaxID\n",
    "def batch_get_phylum(taxon_dict, batch_size=100):\n",
    "    all_taxids = [int(tid) for tid in taxon_dict.keys() if tid != \"-1\"]\n",
    "    taxon_phylum_map = {\"-1\": \"Unknown\"}\n",
    "\n",
    "    for i in range(0, len(all_taxids), batch_size):\n",
    "        batch = all_taxids[i:i + batch_size]\n",
    "        print(f\"🔍 Processing batch {i+1} to {i+len(batch)} of {len(all_taxids)}...\")\n",
    "\n",
    "        xml_data = fetch_phylum_batch(batch)\n",
    "        if not xml_data:\n",
    "            # Retry once after delay\n",
    "            time.sleep(1)\n",
    "            xml_data = fetch_phylum_batch(batch)\n",
    "            if not xml_data:\n",
    "                for tid in batch:\n",
    "                    taxon_phylum_map[str(tid)] = \"Error\"\n",
    "                continue\n",
    "\n",
    "        # Parse each Taxon block individually\n",
    "        root = ET.fromstring(xml_data)\n",
    "        for taxon in root.findall(\"Taxon\"):\n",
    "            tid = taxon.findtext(\"TaxId\")\n",
    "            phylum_name = \"phylum_Not_Found\"\n",
    "\n",
    "            for ancestor in taxon.findall(\".//LineageEx/Taxon\"):\n",
    "                if ancestor.findtext(\"Rank\") == \"phylum\":\n",
    "                    phylum_name = ancestor.findtext(\"ScientificName\")\n",
    "                    break\n",
    "\n",
    "            taxon_phylum_map[tid] = phylum_name\n",
    "\n",
    "        time.sleep(0.34)  # NCBI rate limit: keep <3 requests/sec\n",
    "\n",
    "    return taxon_phylum_map\n",
    "\n",
    "# === Example usage\n",
    "# taxon_dict = {\"562\": \"Escherichia coli\", \"1280\": \"Lactobacillus\", ...}\n",
    "output_dict = batch_get_phylum(taxon_dict, batch_size=100)\n",
    "\n",
    "unique_values = set(output_dict.values())\n",
    "print(f\"Number of unique values: {len(unique_values)}\")\n",
    "\n",
    "# === Save to JSON\n",
    "with open(\"/mnt/iusers01/fatpou01/bmh01/msc-bioinf-2024-2025/h44063jg/gmp_jms/taxon_phyla_dict.json\", \"w\") as f:\n",
    "    json.dump(output_dict, f, indent=2)\n",
    "\n",
    "print(\"✅ Done! Orders saved to 'taxon_to_phyla.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mam_myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
